<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1. Linear Algebra on Lab.Koreanbear|한국곰연구소</title>
    <link>https://koreanbear89.github.io/categories/1.-linear-algebra/</link>
    <description>Recent content in 1. Linear Algebra on Lab.Koreanbear|한국곰연구소</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 27 Jun 2020 09:00:13 +0000</lastBuildDate>
    
        <atom:link href="https://koreanbear89.github.io/categories/1.-linear-algebra/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>NLP #2 | Language Representation </title>
      <link>https://koreanbear89.github.io/research/5.-natural-language/nlp-2-language-representations/</link>
      <pubDate>Wed, 13 Jan 2021 09:00:00 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/research/5.-natural-language/nlp-2-language-representations/</guid>
      <description>0. Introduction Conventional Encoding : Integer encoding, Sparse Representation : One-hot encoding, Document Term Matrix Word Embedding (Dense Representation): Word2Vec, Glove, FastText Pretraind Word Embedding : ELMo, GPT, BERT 1. Conventional Encoding Integer Encoding : 단어를 빈도수 순으로 정렬한 단어 집합을 만들고, 빈도수가 높은 순서대로정수를 부</description>
    </item>
    
    <item>
      <title>CheatSheet | Matplotlib</title>
      <link>https://koreanbear89.github.io/engineering/1.-tools/210112-cheatsheet-matplotlib/</link>
      <pubDate>Tue, 12 Jan 2021 09:00:00 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/engineering/1.-tools/210112-cheatsheet-matplotlib/</guid>
      <description>0. Interface pyplot interface : Rely on pyplot to automatically create and manage the figures and axes, and use pyplot functions for plotting. (MATLAB-like interface) object-oriented interface : Explicitly create figures and axes, and call methods on them import matplotlib.pyplot as plt import numpy as np # pyplot interface (MATLAB-like, rely on pyplot) # x = np.linspace(0,2,100) # plt.plot(x,x**2) # Recommended) object-oriented interface (create figures and axes manually) fig, ax</description>
    </item>
    
    <item>
      <title>NLP #1 | Text Preprocessing</title>
      <link>https://koreanbear89.github.io/research/5.-natural-language/nlp-1-text-preprocessing/</link>
      <pubDate>Tue, 05 Jan 2021 09:00:00 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/research/5.-natural-language/nlp-1-text-preprocessing/</guid>
      <description>0. Introduction 일반적으로 NLP modeling 은 다음과 같은 방식으로 진행 Text Processing : 주어진 데이터 (Corpus) 를 필요에 따라 전처리하고 적합한 (단어) 단위로 Tokenization Text Representation : Word Embedding 과 같은 방법을 활용하여 자연</description>
    </item>
    
    <item>
      <title>Cheat Sheet | Spark</title>
      <link>https://koreanbear89.github.io/engineering/3.-spark/201211-cheatsheet-spark/</link>
      <pubDate>Fri, 11 Dec 2020 09:00:00 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/engineering/3.-spark/201211-cheatsheet-spark/</guid>
      <description>1. Initialization &amp;amp; Configuration SparkContext : provides connection to Spark with the ability to create RDDs SQLContext : procides connection to Spark with the ability to run SQL queries on data SparkSession : all encompassing context which includes coverage for SparkContext, SQLContext and HiveContext import pyspark from pyspark import SparkContext from pyspark.sql import SparkSession from pyspark.sql import SQLContext # create a SparkSession instance with the name &#39;appname&#39; spark = SparkSession.builder.appName(&amp;quot;appname&amp;quot;).getOrCreate()</description>
    </item>
    
    <item>
      <title>How to install pySpark locally</title>
      <link>https://koreanbear89.github.io/engineering/3.-spark/201209-install-spark-locally/</link>
      <pubDate>Wed, 09 Dec 2020 09:00:00 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/engineering/3.-spark/201209-install-spark-locally/</guid>
      <description>1. Prerequisite   Check java version first
  Then, just install miniconda3 and create virtual environment based on python 3.6
java -version # The command above might show something like below &amp;gt;&amp;gt; openjdk version &amp;quot;1.8.0_262&amp;quot; &amp;gt;&amp;gt; OpenJDK Runtime Environment (build 1.8.0_262-b10) &amp;gt;&amp;gt; OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode)    2. Download Spark # Download spark wget https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz # unzip tar -xvzf spark-3.0.1-bin-hadoop2.7.tgz # move to home and rename mv spark-3.</description>
    </item>
    
    <item>
      <title>How to setup vim</title>
      <link>https://koreanbear89.github.io/engineering/2.-linux/how-to-set-up-vim/</link>
      <pubDate>Tue, 08 Dec 2020 09:00:00 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/engineering/2.-linux/how-to-set-up-vim/</guid>
      <description>1. Install Vundle $ git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim 2. color scheme setup Jellybean color scheme official install And simply add line color jellybean in .vimrc mkdir -p ~/.vim/colors cd ~/.vim/colors curl -O https://raw.githubusercontent.com/nanotech/jellybeans.vim/master/colors/jellybeans.vim 3. write .vimrc wget https://raw.githubusercontent.com/jjeaby/jscript/master/.vimrc 로 preset을 받음 Added Plugin &#39;preservim/nerdcommenter&#39; 4. vimrc에 설정한 플러그인 설치 :PluginInstall 로 설</description>
    </item>
    
    <item>
      <title>CheatSheet | SQL basic</title>
      <link>https://koreanbear89.github.io/engineering/1.-tools/201207-cheatsheet-sql-basic/</link>
      <pubDate>Sun, 06 Dec 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/engineering/1.-tools/201207-cheatsheet-sql-basic/</guid>
      <description>Introduction Structured Query Language, SQL 은 관계형 데이터베이스 관리 시스템(RDBMS)의 데이터를 관리하기 위해 설계된 특수 목적의 프로그래밍 언어이다. Commands SELECT : 데이터베이스에서 데이터</description>
    </item>
    
    <item>
      <title>CheatSheet | Docker</title>
      <link>https://koreanbear89.github.io/engineering/1.-tools/cheatsheet-docker/</link>
      <pubDate>Tue, 10 Nov 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/engineering/1.-tools/cheatsheet-docker/</guid>
      <description>Introduction docker docker compose Glossary swarm : cluster 와 동일한 개념 node (manager/worker) : 클러스터에 속한 서버의 단위. 스웜 명령어는 매니저 노드에서만 실행된다 service : 각 프로젝트를 구성하고 있는 서비스 단위 정도,</description>
    </item>
    
    <item>
      <title>MLCV #9 | 3D Object Detection</title>
      <link>https://koreanbear89.github.io/research/3.-computer-vision/cv09-3d-object-detection/</link>
      <pubDate>Tue, 06 Oct 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/research/3.-computer-vision/cv09-3d-object-detection/</guid>
      <description>Summary 3D object detection : classifies the object category and estimates oriented 3D bounding boxes of physical objects from 3D sensor data. Applications : By extending prediction to 3D, one can capture an object’s size, position and orientation in the world, leading to a variety of applications in robotics, self-driving vehicles, image retrieval, and augmented reality Benchmarks KITTI (car, cyclist, pedestrian easy, mod,</description>
    </item>
    
    <item>
      <title>Linear Algebra for ML #6 | PCA </title>
      <link>https://koreanbear89.github.io/mathematics/1.-linear-algebra/2020-06-27-linear-algebra-for-ml-pca/</link>
      <pubDate>Sat, 27 Jun 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/mathematics/1.-linear-algebra/2020-06-27-linear-algebra-for-ml-pca/</guid>
      <description>6.1 Principal Component Analysis Principal component analysis (PCA) : is the process of computing the principal components and using them to perform a change of basis on the data, sometimes using only the first few principal components and ignoring the rest. Principal components : of a collection of n-dim data points are a sequence of $n$ unit vectors, where the $i$-th vector is the direction of a line that best</description>
    </item>
    
    <item>
      <title>Bayesian statistics #2 | MLE and MAP</title>
      <link>https://koreanbear89.github.io/mathematics/2.-statistics/200623-bayes2-mle-and-map/</link>
      <pubDate>Tue, 23 Jun 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/mathematics/2.-statistics/200623-bayes2-mle-and-map/</guid>
      <description>1. Introduction 앞서 Bayes&amp;rsquo; Rule을 이용한 방식의 단점은 likelihood의 probability distribution을 알고있어야 한다는 점인데, 관찰을 통해 likelihoo</description>
    </item>
    
    <item>
      <title>2020 | CVPR</title>
      <link>https://koreanbear89.github.io/engineering/9.-others/2020-06-17-2020-cvpr/</link>
      <pubDate>Wed, 17 Jun 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/engineering/9.-others/2020-06-17-2020-cvpr/</guid>
      <description>Overview New Topics : Explainable AI, Fairness, Accountability, Transparency and Ethics in Vision Recognition &amp;gt; Learning Methods &amp;gt; Face, Gesture, Body Pose &amp;gt; Img and Video Synthesis &amp;hellip; Young Researcher Award : Jon Barron and Deqing Sun Best Paper Award : Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the wild Best Studen Paper Award : BSP-Net: Generating Compact Meshes via Binary Space Partitioning Best Stud Honorable</description>
    </item>
    
    <item>
      <title>Bayesian statistics #1 | Bayes&#39; Rule</title>
      <link>https://koreanbear89.github.io/mathematics/2.-statistics/200609-bayes1-bayes-rule/</link>
      <pubDate>Tue, 09 Jun 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/mathematics/2.-statistics/200609-bayes1-bayes-rule/</guid>
      <description>1. Introduction 연역적 추론(Freq) 에서 귀납적 추론(Bayes) 으로의 확률론 패러다임의 전환 Frequentist View : 확률을 &amp;lsquo;발생하는 현상의 빈도수&amp;rsquo;</description>
    </item>
    
    <item>
      <title>CheatSheet | Python Basic</title>
      <link>https://koreanbear89.github.io/engineering/1.-tools/160601-cheatsheet-python-basic/</link>
      <pubDate>Sat, 30 May 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/engineering/1.-tools/160601-cheatsheet-python-basic/</guid>
      <description>1. Python Basic Data Type 1.1 Number a**b # 제곱 a//b # 몫 a%b # 나머지 1.2 String &amp;gt;&amp;gt;&amp;gt; y = 3.42134234 &amp;gt;&amp;gt;&amp;gt; &amp;quot;{0:0.4f}&amp;quot;.format(y) # 문자열포맷 &#39;3.4213&#39; 1.3 List a = [1,2,3] b = [4,5,6] # 1. 리스트 더하기 &amp;gt;&amp;gt;&amp;gt; a + b : [1,2,3,4,5,6] # 2. 리스트 반복 &amp;gt;&amp;gt;&amp;gt; a*3 : [1,2,3,1,2,3,1,2,3] 1.4 Tuple 튜</description>
    </item>
    
    <item>
      <title>CheatSheet | Jekyll</title>
      <link>https://koreanbear89.github.io/engineering/1.-tools/200418-cheatsheet-jekyll/</link>
      <pubDate>Sat, 18 Apr 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/engineering/1.-tools/200418-cheatsheet-jekyll/</guid>
      <description>0. Install RVM &amp;amp; Ruby $ sudo apt-get update $ sudo apt-get install -y curl gnupg build-essential $ sudo gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 $ curl -sSL https://get.rvm.io | sudo bash -s stable $ sudo usermod -a -G rvm `whoami` $ rvm install ruby-X.X.X $ rvm --default use ruby-X.X.X $ gem install bundler --no-rdoc --no-ri # If bash cannot find ruby, $ source /etc/profile  
1. Install MathJax   Problem: MathJax does not work</description>
    </item>
    
    <item>
      <title>Statistics #8 | Covariance and Correlation</title>
      <link>https://koreanbear89.github.io/mathematics/2.-statistics/200227-all-of-stats8_covariance/</link>
      <pubDate>Thu, 27 Feb 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/mathematics/2.-statistics/200227-all-of-stats8_covariance/</guid>
      <description>1. Covariance 두 확률변수 사이의 상관성/의존성/유사성의 방향 및 정도에 대한 척도, 즉 데이터간의 관계성을 정량화한 정도. 이때의 관계성은 일반적으로 선형 관계성만을 의</description>
    </item>
    
    <item>
      <title>Statistics #6 | Models, Statistical Inference and Learning </title>
      <link>https://koreanbear89.github.io/mathematics/2.-statistics/200202-all-of-statistics-ch6/</link>
      <pubDate>Sun, 02 Feb 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/mathematics/2.-statistics/200202-all-of-statistics-ch6/</guid>
      <description>6.1 Introduction  Statistical Inference, or &amp;ldquo;learning&amp;rdquo; as it is called in computer science, is the process of using data to infer distribution that generated the data.  6.2 Parametric and Nonparametric Models   A statistical model $\Im$ is a set of distributions (or densities or regression functions)
  Parametric model : is a set of $\Im$ that can be parameterized by a finite number of parameters
  If we assume that the data come from a Normal distribution, then It would be two-prarmeter model.</description>
    </item>
    
    <item>
      <title>Statistics #5 | Convergence of Random Variable </title>
      <link>https://koreanbear89.github.io/mathematics/2.-statistics/200130-all-of-statistics-ch5/</link>
      <pubDate>Thu, 30 Jan 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/mathematics/2.-statistics/200130-all-of-statistics-ch5/</guid>
      <description>5.1 Introduction   The law of large numbers says that the sample average converges in proability to the expectation $ \mu = \mathbb{E}(X_i)$
  The central limit theorem says that $ \sqrt{n} (\overline{X - \mu})$ converges in distribution to a Normal distribution.
  5.2 Types of Convergence  $X_n$ converges to $X$ in probability, written $X_n \xrightarrow{P}{} X$ if for every $\epsilon &amp;gt; 0$  $$ \mathbb{P}(|X_n - X| &amp;gt; \epsilon) \rightarrow 0$$</description>
    </item>
    
    <item>
      <title>Statistics #4 | Probability Inequalities </title>
      <link>https://koreanbear89.github.io/mathematics/2.-statistics/200129-all-of-statistics-ch4/</link>
      <pubDate>Wed, 29 Jan 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/mathematics/2.-statistics/200129-all-of-statistics-ch4/</guid>
      <description>4.1 Probability Inequalities   Inequalities are useful for bounding quantities that might otherwise be hard to compute.
  Markov&amp;rsquo;s inequality : Let $X$ be a non-negative random variable and suppose that $\mathbb{E}(X)$ exists. For any $t&amp;gt;0$,
  $$\mathbb{P}(X&amp;gt;t) \leq \frac{\mathbb{E}(X)}{t}$$
 Chebyshev&amp;rsquo;s inequality : Let $\mu = \mathbb{E}(X)$ and $\sigma^2 = \mathbb{V}(X)$  $$ \mathbb{P}(| X-\mu| \geq t) \leq \frac{\sigma^2}{t^2} \ \text{and} \mathbb{P}(|Z| \geq k) \leq \frac{1}{k^2}$$</description>
    </item>
    
    <item>
      <title>Statistics #3 | Expectation </title>
      <link>https://koreanbear89.github.io/mathematics/2.-statistics/200128-all-of-statistics-ch3/</link>
      <pubDate>Tue, 28 Jan 2020 09:00:13 +0000</pubDate>
      
      <guid>https://koreanbear89.github.io/mathematics/2.-statistics/200128-all-of-statistics-ch3/</guid>
      <description>3.1 Expectation of a Random Variable  The expected value, or mean, or first moment of $X$ is defined to be  $$ \mathbb{E}(X) = \int xdF(x) = \begin{cases} \sum_x xf(x) &amp;amp; (\text{if X is discrete})\ \int xf(x)dx &amp;amp; ( \text{if X is continuous}) \end{cases}$$
3.3 Variance and Covariance  The variance measures the spread of a distribution  $$ \sigma^2 = \mathbb{E}(X-\mu)^2 = \int (x-\mu)^2 dF(x) $$
 The covariance and correlation between $X$ and $Y$ measure how strong the linear relationship is between $X$ and $Y$  $$\text{Cov}(X,Y) = \mathbb{E}((X-\mu_X)(Y- \mu_Y ))$$</description>
    </item>
    
  </channel>
</rss>
